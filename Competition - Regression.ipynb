{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "X_train_raw = pd.read_csv('D:/Downloads/Competition/regression_comp_starter_kit/Header - train.txt')\n",
    "X_test_raw = pd.read_csv('D:/Downloads/Competition/regression_comp_starter_kit/Header - test.txt')\n",
    "y_train_raw = pd.read_csv('D:/Downloads/Competition/regression_comp_starter_kit/Viking - Train.txt')\n",
    "X_validate_raw = pd.read_csv('D:/Downloads/Competition/regression_comp_starter_kit//Header - validation.txt')\n",
    "y_validate_raw = pd.read_csv('D:/Downloads/Competition/regression_comp_starter_kit/Viking - Validation.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rows and columns of independent variable is  (588673, 90)\n",
      "the raw and coulmn of the dependent variable is  (6256, 6)\n",
      "the raw and coulmn of the dependent variable is  (118076, 90)\n"
     ]
    }
   ],
   "source": [
    "print('The rows and columns of independent variable is ', X_train_raw.shape)\n",
    "print('the raw and coulmn of the dependent variable is ' , y_train_raw.shape)\n",
    "print('the raw and coulmn of the dependent variable is ' , X_test_raw.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z=pd.merge(X_train_raw, y_train_raw , on='EPAssetsId' ,how='inner')\n",
    "ZV=pd.merge(X_validate_raw, y_validate_raw , on='EPAssetsId' ,how='inner')\n",
    "ZVV=X_test_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Z['SurfAbandon']=np.where(Z.SurfAbandonDate.isnull(),0,1)\n",
    "ZV['SurfAbandon']=np.where(ZV.SurfAbandonDate.isnull(),0,1)\n",
    "ZVV['SurfAbandon']=np.where(ZVV.SurfAbandonDate.isnull(),0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z['_Fracture`Stages']=Z['_Fracture`Stages'].replace(np.nan,0)\n",
    "Z['_Completion`Events']=Z['_Completion`Events'].replace(np.nan,0)\n",
    "Z['ProjectedDepth']=Z['ProjectedDepth'].replace(np.nan,Z.ProjectedDepth.mean())\n",
    "Z['TVD']=Z['TVD'].replace(np.nan,0)\n",
    "Z['Surf_Longitude']=Z['Surf_Longitude'].replace(np.nan,Z.Surf_Longitude.mean())\n",
    "Z['Surf_Latitude']=Z['Surf_Latitude'].replace(np.nan,Z.Surf_Latitude.mean())\n",
    "\n",
    "Z['_Max`Prod`(BOE)']=Z['_Max`Prod`(BOE)'].replace(np.nan,Z['_Max`Prod`(BOE)'].mean())\n",
    "Z['_Normalized`IP`(Oil`-`Bbls)']=Z['_Normalized`IP`(Oil`-`Bbls)'].replace(np.nan,0)\n",
    "Z['_Normalized`IP`Gas`(Boe/d)']=Z['_Normalized`IP`Gas`(Boe/d)'].replace(np.nan,0)\n",
    "Z['_Normalized`IP`(Water`-`Bbls)']=Z['_Normalized`IP`(Water`-`Bbls)'].replace(np.nan,0)\n",
    "ZV['_Normalized`IP`(Oil`-`Bbls)']=ZV['_Normalized`IP`(Oil`-`Bbls)'].replace(np.nan,0)\n",
    "ZV['_Normalized`IP`Gas`(Boe/d)']=ZV['_Normalized`IP`Gas`(Boe/d)'].replace(np.nan,0)\n",
    "ZV['_Normalized`IP`(Water`-`Bbls)']=ZV['_Normalized`IP`(Water`-`Bbls)'].replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#collinearity between predictors\\ncorr =df.corr()\\nplt.figure(figsize = (16,12))\\nsns.heatmap(corr, \\n            xticklabels=corr.columns.values,\\n            yticklabels=corr.columns.values)\\n# colinearity between fracture stages and completion events(Fracture stages will be dropped)\\n# colinearity between TotalDepth , TVD and projected depth TotalDepth and ProjectedDepth will be dropped)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#collinearity between predictors\n",
    "corr =df.corr()\n",
    "plt.figure(figsize = (16,12))\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "# colinearity between fracture stages and completion events(Fracture stages will be dropped)\n",
    "# colinearity between TotalDepth , TVD and projected depth TotalDepth and ProjectedDepth will be dropped)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# save correlations to variable\\ncorr = df.corr()\\n# we can create a mask to not show duplicate values\\nmask = np.zeros_like(corr, dtype=np.bool)\\nmask[np.triu_indices_from(mask)] = True\\n# generate heatmap\\nplt.figure(figsize= (12,12))\\nsns.heatmap(corr, annot=True, center=0, mask=mask, cmap='gnuplot')\\nplt.show()\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# save correlations to variable\n",
    "corr = df.corr()\n",
    "# we can create a mask to not show duplicate values\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "# generate heatmap\n",
    "plt.figure(figsize= (12,12))\n",
    "sns.heatmap(corr, annot=True, center=0, mask=mask, cmap='gnuplot')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncorr_list = sorted(df.corr().to_dict()['_Normalized`IP`(Oil`-`Bbls)'].items(), key=lambda x: x[1], reverse=True)\\ncorr_list\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "corr_list = sorted(df.corr().to_dict()['_Normalized`IP`(Oil`-`Bbls)'].items(), key=lambda x: x[1], reverse=True)\n",
    "corr_list'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor col in df:\\n    if(df[col].dtype == np.float64 or df[col].dtype == np.int64):\\n        sns.regplot(x=df[col], y=target, data=df, label=col)\\n        plt.ylabel('Oil Production')\\n        plt.xlabel(col)\\n        plt.legend()\\n        plt.tight_layout()\\n        plt.show()\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for col in df:\n",
    "    if(df[col].dtype == np.float64 or df[col].dtype == np.int64):\n",
    "        sns.regplot(x=df[col], y=target, data=df, label=col)\n",
    "        plt.ylabel('Oil Production')\n",
    "        plt.xlabel(col)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)\\nplt.show()'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z.LaheeClass.replace(['Confidential', 'Development Service Well','Non Issued Licence'],'Development',inplace=True)\n",
    "Z.LaheeClass.replace(['Deeper Pool Test', 'Experimental','Oil Sands Evaluation','Potash Test Hole','Re-entry','Shallower Pool Test','Test Hole'],'Test',inplace=True)\n",
    "Z.LaheeClass.replace(['New Pool Wildcat', 'New Field Wildcat','Deeper Pool Wildcat'],'WildCat',inplace=True)\n",
    "\n",
    "ZV.LaheeClass.replace(['Confidential', 'Development Service Well','Non Issued Licence'],'Development',inplace=True)\n",
    "ZV.LaheeClass.replace(['Deeper Pool Test', 'Experimental','Oil Sands Evaluation','Potash Test Hole','Re-entry','Shallower Pool Test','Test Hole'],'Test',inplace=True)\n",
    "ZV.LaheeClass.replace(['New Pool Wildcat', 'New Field Wildcat','Deeper Pool Wildcat'],'WildCat',inplace=True)\n",
    "\n",
    "\n",
    "ZVV.LaheeClass.replace(['Confidential', 'Development Service Well','Non Issued Licence',],'Development',inplace=True)\n",
    "ZVV.LaheeClass.replace(['Deeper Pool Test', 'Experimental','Oil Sands Evaluation','Potash Test Hole','Re-entry','Shallower Pool Test','Test Hole'],'Test',inplace=True)\n",
    "ZVV.LaheeClass.replace(['New Pool Wildcat', 'New Field Wildcat','Deeper Pool Wildcat'],'WildCat',inplace=True)\n",
    "ZVV.LaheeClass.replace(['Unspecified'],'Other',inplace=True)\n",
    "ZV.loc[1,'LaheeClass']='Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZVV['TotalDepth']=ZVV['TotalDepth'].fillna(0)\n",
    "Z['TotalDepth']=Z['TotalDepth'].fillna(0)\n",
    "ZV['TotalDepth']=ZV['TotalDepth'].fillna(0)\n",
    "ZVV['TVD']=ZVV['TVD'].fillna(1)\n",
    "Z['TVD']=Z['TVD'].fillna(1)\n",
    "ZV['TVD']=ZV['TVD'].fillna(1)\n",
    "ZVV['TVD']=ZVV['TVD'].replace(0,1)\n",
    "Z['TVD']=Z['TVD'].replace(0,1)\n",
    "ZV['TVD']=ZV['TVD'].replace(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z['MD/TVD']=Z['TotalDepth']/Z['TVD']\n",
    "ZV['MD/TVD']=ZV['TotalDepth']/ZV['TVD']\n",
    "ZVV['MD/TVD']=ZVV['TotalDepth']/ZVV['TVD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z['MD/TVD']=Z['MD/TVD'].fillna(0)\n",
    "ZV['MD/TVD']=ZV['MD/TVD'].fillna(0)\n",
    "ZVV['MD/TVD']=ZVV['MD/TVD'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZVV.WellProfile.replace('Slant','Directional',inplace=True)\n",
    "ZVV.WellProfile.replace('Horizontal Leg','Horizontal',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z['_Fracture`Stages']=Z['_Fracture`Stages'].fillna(0)\n",
    "ZV['_Fracture`Stages']=ZV['_Fracture`Stages'].fillna(0)\n",
    "ZVV['_Fracture`Stages']=ZVV['_Fracture`Stages'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_Select = ['EPAssetsId', 'Formation' , 'TotalDepth' , 'LaheeClass' , \"TVD\", \"WellProfile\" , '_Open`Hole']\n",
    "\n",
    "#,'_Open`Hole' not effective\n",
    "#replace TVD with MD/TVD    ,,, ,'_Fracture`Stages'\n",
    "# 'TVD' & 'SurfAbandon' &\"WellProfile\" & '_Fracture`Stages'  gives negative for col 1 & 2\n",
    "# 'Surf_Longitude' gives negative for col 1 \n",
    "\n",
    "X_Select =['EPAssetsId','_Max`Prod`(BOE)', 'Surf_Latitude','TotalDepth','LaheeClass']\n",
    "X_train = Z[X_Select ]\n",
    "X_validate = ZV[X_Select ]\n",
    "X_test= ZVV[X_Select ]\n",
    "X_Select2 = ['EPAssetsId','Surf_Longitude','_Max`Prod`(BOE)', 'Surf_Latitude','TotalDepth','LaheeClass']\n",
    "X_train2=Z[X_Select2 ]\n",
    "X_validate2 = ZV[X_Select2 ] \n",
    "X_test2= ZVV[X_Select2 ]\n",
    "#'Surf_Longitude',gives negative for DT\n",
    "X_Select3= ['EPAssetsId','Surf_Longitude','_Max`Prod`(BOE)', 'Surf_Latitude','TotalDepth','LaheeClass']\n",
    "X_train3 = Z[X_Select3]\n",
    "X_validate3 = ZV[X_Select3 ] \n",
    "X_test3= ZVV[X_Select3 ]\n",
    "\n",
    "'''X_Select = ['EPAssetsId','Surf_Latitude', '_Max`Prod`(BOE)','TotalDepth']\n",
    "X_train = Z[X_Select ]\n",
    "X_validate = ZV[X_Select ]\n",
    "X_test= ZVV[X_Select ]\n",
    "X_Select2 = ['EPAssetsId','Surf_Longitude','_Max`Prod`(BOE)', 'Surf_Latitude','TotalDepth','LaheeClass']\n",
    "X_train2=Z[X_Select2 ]\n",
    "X_validate2 = ZV[X_Select2 ] \n",
    "X_test2= ZVV[X_Select2 ]\n",
    "#'Surf_Longitude',gives negative for DT\n",
    "X_Select3= ['EPAssetsId', 'Surf_Latitude']\n",
    "X_train3 = Z[X_Select3]\n",
    "X_validate3 = ZV[X_Select3 ] \n",
    "X_test3= ZVV[X_Select3 ]'''\n",
    "\n",
    "y_select=['EPAssetsId', 'well_status_code']\n",
    "\n",
    "\n",
    "Column1 = [ 'EPAssetsId', '_Normalized`IP`(Oil`-`Bbls)']\n",
    "y_train = Z[Column1]\n",
    "y_validate =ZV[Column1]\n",
    "\n",
    "\n",
    "Column2=[ 'EPAssetsId','_Normalized`IP`Gas`(Boe/d)']\n",
    "y_train2=Z[Column2]\n",
    "y_validate2 =ZV[Column2]\n",
    "\n",
    "Column3 =[ 'EPAssetsId','_Normalized`IP`(Water`-`Bbls)']\n",
    "y_train3=Z[Column3]\n",
    "y_validate3 =ZV[Column3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning X_validate & y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#X_validate['_Completion`Events']=X_validate['_Completion`Events'].replace(np.nan, 0)\n",
    "#X_validate['TVD']=X_validate['TVD'].replace(np.nan,0) #X_validate['TVD'].mean()\n",
    "X_validate['_Max`Prod`(BOE)']=X_validate['_Max`Prod`(BOE)'].replace(np.nan,0)#X_validate['_Max`Prod`(BOE)'].mean()\n",
    "X_validate2['_Max`Prod`(BOE)']=X_validate2['_Max`Prod`(BOE)'].replace(np.nan,0)\n",
    "X_validate3['_Max`Prod`(BOE)']=X_validate2['_Max`Prod`(BOE)'].replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#X_test['_Completion`Events']=X_test['_Completion`Events'].replace(np.nan, 0)\n",
    "#X_test['TVD']=X_test['TVD'].replace(np.nan,X_test['TVD'].mean()) \n",
    "X_test['_Max`Prod`(BOE)']=X_test['_Max`Prod`(BOE)'].replace(np.nan,X_test['_Max`Prod`(BOE)'].mean())\n",
    "X_test2['_Max`Prod`(BOE)']=X_test2['_Max`Prod`(BOE)'].replace(np.nan,X_test['_Max`Prod`(BOE)'].mean())\n",
    "X_test3['_Max`Prod`(BOE)']=X_test2['_Max`Prod`(BOE)'].replace(np.nan,X_test['_Max`Prod`(BOE)'].mean())\n",
    "X_test['Surf_Latitude']=X_test['Surf_Latitude'].replace(np.nan,X_test['Surf_Latitude'].mean())\n",
    "X_test2['Surf_Latitude']=X_test2['Surf_Latitude'].replace(np.nan,X_test2['Surf_Latitude'].mean())\n",
    "X_test3['Surf_Latitude']=X_test3['Surf_Latitude'].replace(np.nan,X_test3['Surf_Latitude'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding - the code dropped the original column!\n",
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]],drop_first=True)\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    res = res.drop([feature_to_encode], axis=1)\n",
    "    return(res)\n",
    "X_train=encode_and_bind(X_train, \"LaheeClass\")\n",
    "X_train2=encode_and_bind(X_train2, \"LaheeClass\")\n",
    "X_train3=encode_and_bind(X_train3, \"LaheeClass\")\n",
    "#X_train=encode_and_bind(X_train, \"WellProfile\")\n",
    "#X_train=encode_and_bind(X_train, '_Open`Hole')\n",
    "#X_train=encode_and_bind(X_train, 'WellTypeStandardised')\n",
    "\n",
    "#X_train=encode_and_bind(X_train, 'Formation')\n",
    "#X_train=encode_and_bind(X_train, 'PSACAreaName')\n",
    "X_validate=encode_and_bind(X_validate, \"LaheeClass\")\n",
    "X_validate2=encode_and_bind(X_validate2, \"LaheeClass\")\n",
    "X_validate3=encode_and_bind(X_validate3, \"LaheeClass\")\n",
    "#X_validate=encode_and_bind(X_validate, \"WellProfile\")\n",
    "#X_validate=encode_and_bind(X_validate, '_Open`Hole')\n",
    "#X_validate=encode_and_bind(X_validate, 'WellTypeStandardised')\n",
    "#X_validate=encode_and_bind(X_validate, 'Formation')\n",
    "#X_validate=encode_and_bind(X_validate, 'PSACAreaName')\n",
    "X_test=encode_and_bind(X_test, \"LaheeClass\")\n",
    "X_test2=encode_and_bind(X_test2, \"LaheeClass\")\n",
    "X_test3=encode_and_bind(X_test3, \"LaheeClass\")\n",
    "#X_test=encode_and_bind(X_test, \"WellProfile\")\n",
    "#X_test=encode_and_bind(X_test, '_Open`Hole')\n",
    "#X_test=encode_and_bind(X_test, 'WellTypeStandardised')\n",
    "#X_test=encode_and_bind(X_test, 'Formation')\n",
    "#X_train=encode_and_bind(X_test, 'PSACAreaName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPAssetsId</th>\n",
       "      <th>_Max`Prod`(BOE)</th>\n",
       "      <th>Surf_Latitude</th>\n",
       "      <th>TotalDepth</th>\n",
       "      <th>LaheeClass_Other</th>\n",
       "      <th>LaheeClass_Outpost</th>\n",
       "      <th>LaheeClass_Test</th>\n",
       "      <th>LaheeClass_WildCat</th>\n",
       "      <th>EPAssetsId</th>\n",
       "      <th>_Normalized`IP`(Oil`-`Bbls)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EPAssetsId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162752</td>\n",
       "      <td>0.668547</td>\n",
       "      <td>0.473162</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>-0.111741</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>-0.020261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_Max`Prod`(BOE)</th>\n",
       "      <td>0.162752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057138</td>\n",
       "      <td>0.403845</td>\n",
       "      <td>0.605654</td>\n",
       "      <td>-0.077592</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>-0.032409</td>\n",
       "      <td>0.162752</td>\n",
       "      <td>0.255860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surf_Latitude</th>\n",
       "      <td>0.668547</td>\n",
       "      <td>0.057138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.227713</td>\n",
       "      <td>0.041106</td>\n",
       "      <td>-0.075540</td>\n",
       "      <td>0.022615</td>\n",
       "      <td>-0.022260</td>\n",
       "      <td>0.668547</td>\n",
       "      <td>-0.091836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalDepth</th>\n",
       "      <td>0.473162</td>\n",
       "      <td>0.403845</td>\n",
       "      <td>0.227713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066614</td>\n",
       "      <td>-0.073745</td>\n",
       "      <td>0.054512</td>\n",
       "      <td>0.016102</td>\n",
       "      <td>0.473162</td>\n",
       "      <td>0.125218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LaheeClass_Other</th>\n",
       "      <td>0.021525</td>\n",
       "      <td>0.605654</td>\n",
       "      <td>0.041106</td>\n",
       "      <td>0.066614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003008</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>-0.001123</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>-0.016869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LaheeClass_Outpost</th>\n",
       "      <td>-0.111741</td>\n",
       "      <td>-0.077592</td>\n",
       "      <td>-0.075540</td>\n",
       "      <td>-0.073745</td>\n",
       "      <td>-0.003008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003008</td>\n",
       "      <td>-0.021134</td>\n",
       "      <td>-0.111741</td>\n",
       "      <td>-0.140016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LaheeClass_Test</th>\n",
       "      <td>0.019880</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>0.022615</td>\n",
       "      <td>0.054512</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>-0.003008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001123</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>-0.015809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LaheeClass_WildCat</th>\n",
       "      <td>-0.020261</td>\n",
       "      <td>-0.032409</td>\n",
       "      <td>-0.022260</td>\n",
       "      <td>0.016102</td>\n",
       "      <td>-0.001123</td>\n",
       "      <td>-0.021134</td>\n",
       "      <td>-0.001123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020261</td>\n",
       "      <td>-0.081986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPAssetsId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162752</td>\n",
       "      <td>0.668547</td>\n",
       "      <td>0.473162</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>-0.111741</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>-0.020261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_Normalized`IP`(Oil`-`Bbls)</th>\n",
       "      <td>-0.003447</td>\n",
       "      <td>0.255860</td>\n",
       "      <td>-0.091836</td>\n",
       "      <td>0.125218</td>\n",
       "      <td>-0.016869</td>\n",
       "      <td>-0.140016</td>\n",
       "      <td>-0.015809</td>\n",
       "      <td>-0.081986</td>\n",
       "      <td>-0.003447</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             EPAssetsId  _Max`Prod`(BOE)  Surf_Latitude  \\\n",
       "EPAssetsId                     1.000000         0.162752       0.668547   \n",
       "_Max`Prod`(BOE)                0.162752         1.000000       0.057138   \n",
       "Surf_Latitude                  0.668547         0.057138       1.000000   \n",
       "TotalDepth                     0.473162         0.403845       0.227713   \n",
       "LaheeClass_Other               0.021525         0.605654       0.041106   \n",
       "LaheeClass_Outpost            -0.111741        -0.077592      -0.075540   \n",
       "LaheeClass_Test                0.019880        -0.005339       0.022615   \n",
       "LaheeClass_WildCat            -0.020261        -0.032409      -0.022260   \n",
       "EPAssetsId                     1.000000         0.162752       0.668547   \n",
       "_Normalized`IP`(Oil`-`Bbls)   -0.003447         0.255860      -0.091836   \n",
       "\n",
       "                             TotalDepth  LaheeClass_Other  LaheeClass_Outpost  \\\n",
       "EPAssetsId                     0.473162          0.021525           -0.111741   \n",
       "_Max`Prod`(BOE)                0.403845          0.605654           -0.077592   \n",
       "Surf_Latitude                  0.227713          0.041106           -0.075540   \n",
       "TotalDepth                     1.000000          0.066614           -0.073745   \n",
       "LaheeClass_Other               0.066614          1.000000           -0.003008   \n",
       "LaheeClass_Outpost            -0.073745         -0.003008            1.000000   \n",
       "LaheeClass_Test                0.054512         -0.000160           -0.003008   \n",
       "LaheeClass_WildCat             0.016102         -0.001123           -0.021134   \n",
       "EPAssetsId                     0.473162          0.021525           -0.111741   \n",
       "_Normalized`IP`(Oil`-`Bbls)    0.125218         -0.016869           -0.140016   \n",
       "\n",
       "                             LaheeClass_Test  LaheeClass_WildCat  EPAssetsId  \\\n",
       "EPAssetsId                          0.019880           -0.020261    1.000000   \n",
       "_Max`Prod`(BOE)                    -0.005339           -0.032409    0.162752   \n",
       "Surf_Latitude                       0.022615           -0.022260    0.668547   \n",
       "TotalDepth                          0.054512            0.016102    0.473162   \n",
       "LaheeClass_Other                   -0.000160           -0.001123    0.021525   \n",
       "LaheeClass_Outpost                 -0.003008           -0.021134   -0.111741   \n",
       "LaheeClass_Test                     1.000000           -0.001123    0.019880   \n",
       "LaheeClass_WildCat                 -0.001123            1.000000   -0.020261   \n",
       "EPAssetsId                          0.019880           -0.020261    1.000000   \n",
       "_Normalized`IP`(Oil`-`Bbls)        -0.015809           -0.081986   -0.003447   \n",
       "\n",
       "                             _Normalized`IP`(Oil`-`Bbls)  \n",
       "EPAssetsId                                     -0.003447  \n",
       "_Max`Prod`(BOE)                                 0.255860  \n",
       "Surf_Latitude                                  -0.091836  \n",
       "TotalDepth                                      0.125218  \n",
       "LaheeClass_Other                               -0.016869  \n",
       "LaheeClass_Outpost                             -0.140016  \n",
       "LaheeClass_Test                                -0.015809  \n",
       "LaheeClass_WildCat                             -0.081986  \n",
       "EPAssetsId                                     -0.003447  \n",
       "_Normalized`IP`(Oil`-`Bbls)                     1.000000  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M=pd.concat([X_train , y_train], axis=1)\n",
    "M.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.set_index('EPAssetsId')\n",
    "X_train2=X_train2.set_index('EPAssetsId')\n",
    "X_train3=X_train3.set_index('EPAssetsId')\n",
    "X_validate=X_validate.set_index('EPAssetsId')\n",
    "X_validate2=X_validate2.set_index('EPAssetsId')\n",
    "X_validate3=X_validate3.set_index('EPAssetsId')\n",
    "X_test=X_test.set_index('EPAssetsId')\n",
    "X_test2=X_test2.set_index('EPAssetsId')\n",
    "X_test3=X_test3.set_index('EPAssetsId')\n",
    "y_train=y_train.set_index('EPAssetsId')\n",
    "y_train2=y_train2.set_index('EPAssetsId')\n",
    "y_train3=y_train3.set_index('EPAssetsId')\n",
    "y_validate=y_validate.set_index('EPAssetsId')\n",
    "y_validate2=y_validate2.set_index('EPAssetsId')\n",
    "y_validate3=y_validate3.set_index('EPAssetsId')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training data is 6.709012715697814\n",
      "MAE for validation data is 6.758216060836333\n",
      "R Squared for train data is 0.14230878003290715\n",
      "R Squared for validation data is 0.05250756450330962\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "y_pred_validate = regressor.predict(X_validate)\n",
    "y_pred_test = regressor.predict(X_test)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE for Training data is', mean_absolute_error(y_train, y_pred_train))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate, y_pred_validate))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train, y_pred_train)) \n",
    "print('R Squared for validation data is', r2_score(y_validate, y_pred_validate) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[113.72983433]\n",
      "[[ 3.93527152e-02 -1.96578884e+00 -1.15606074e-04 -2.09336850e+02\n",
      "  -5.38445318e+00 -9.06688640e+00 -8.51537925e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(regressor.intercept_)\n",
    "print(regressor.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training data is 6.096897007208851\n",
      "MAE for validation data is 6.543918031537887\n",
      "R Squared for train data is 0.6865358014522775\n",
      "R Squared for validation data is 0.21823579605263854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train2, y_train2)\n",
    "y_pred_train2 = regressor.predict(X_train2)\n",
    "y_pred_validate2 = regressor.predict(X_validate2)\n",
    "y_pred_test2= regressor.predict(X_test2)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print('MAE for Training data is', mean_absolute_error(y_train2, y_pred_train2))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate2, y_pred_validate2))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train2, y_pred_train2)) \n",
    "print('R Squared for validation data is', r2_score(y_validate2, y_pred_validate2) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training data is 3.63785818788728\n",
      "MAE for validation data is 3.203232224901129\n",
      "R Squared for train data is 0.04468801433133174\n",
      "R Squared for validation data is -0.01064251942009653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train3, y_train3)\n",
    "y_pred_train3=regressor.predict(X_train3)\n",
    "y_pred_validate3 = regressor.predict(X_validate3)\n",
    "y_pred_test3= regressor.predict(X_test3)\n",
    "print('MAE for Training data is', mean_absolute_error(y_train3, y_pred_train3))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate3, y_pred_validate3))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train3, y_pred_train3)) \n",
    "print('R Squared for validation data is', r2_score(y_validate3, y_pred_validate3) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "ML=X_test_raw[['EPAssetsId','UWI']]\n",
    "ML['_Normalized`IP`(Oil`-`Bbls)']=y_pred_test\n",
    "ML['_Normalized`IP`Gas`(Boe/d)']=y_pred_test2\n",
    "ML['_Normalized`IP`(Water`-`Bbls)']=y_pred_test3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.to_csv('D:/Submit_MultipleLinear.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stepwise Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# SL=0.05\\nimport statsmodels.formula.api as sm\\n# there is no X0 in statsmodel library\\nX_train=np.append(arr=np.ones((6256,1)).astype(int),values=X_train,axis=1)\\nX_opt=X_train[:,[0,1,2,3,4,5,6]]\\nregressor_OLS=sm.OLS(endog=y_train,exog=X_opt ).fit()\\nregressor_OLS.summary()'"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# SL=0.05\n",
    "import statsmodels.formula.api as sm\n",
    "# there is no X0 in statsmodel library\n",
    "X_train=np.append(arr=np.ones((6256,1)).astype(int),values=X_train,axis=1)\n",
    "X_opt=X_train[:,[0,1,2,3,4,5,6]]\n",
    "regressor_OLS=sm.OLS(endog=y_train,exog=X_opt ).fit()\n",
    "regressor_OLS.summary()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_opt=X_train[:,[0,1,2,3,4,5]]\\nregressor_OLS=sm.OLS(endog=y_train,exog=X_opt ).fit()\\nregressor_OLS.summary()'"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X_opt=X_train[:,[0,1,2,3,4,5]]\n",
    "regressor_OLS=sm.OLS(endog=y_train,exog=X_opt ).fit()\n",
    "regressor_OLS.summary()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Polynomial regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training data is 4.925723044051865\n",
      "MAE for validation data is 5.158922192830492\n",
      "R Squared for train data is 0.4982673837383875\n",
      "R Squared for validation data is 0.2385271173872674\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg=PolynomialFeatures(degree=2)\n",
    "X_poly=poly_reg.fit_transform(X_train)\n",
    "X_validate_poly=poly_reg.fit_transform(X_validate)\n",
    "X_test_poly=poly_reg.fit_transform(X_test)\n",
    "lin_reg_2=LinearRegression()\n",
    "lin_reg_2.fit(X_poly,y_train)\n",
    "#prediction\n",
    "y_pred_poly= lin_reg_2.predict(X_poly)\n",
    "y_pred_validate_poly= lin_reg_2.predict(X_validate_poly)\n",
    "y_pred_test= lin_reg_2.predict(X_test_poly)\n",
    "\n",
    "print('MAE for Training data is', mean_absolute_error(y_train, y_pred_poly))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate, y_pred_validate_poly))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train, y_pred_poly)) \n",
    "print('R Squared for validation data is', r2_score(y_validate, y_pred_validate_poly) ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training data is 3.520181806150649\n",
      "MAE for validation data is 4.0212422984886835\n",
      "R Squared for train data is 0.8140939718197601\n",
      "R Squared for validation data is 0.26931444360301515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg=PolynomialFeatures(degree=2)\n",
    "X_poly=poly_reg.fit_transform(X_train2)\n",
    "X_validate_poly=poly_reg.fit_transform(X_validate2)\n",
    "X_test_poly=poly_reg.fit_transform(X_test2)\n",
    "lin_reg_2=LinearRegression()\n",
    "lin_reg_2.fit(X_poly,y_train2)\n",
    "\n",
    "\n",
    "y_pred_poly2= lin_reg_2.predict(X_poly)\n",
    "y_pred_validate_poly2= lin_reg_2.predict(X_validate_poly)\n",
    "y_pred_test2= lin_reg_2.predict(X_test_poly)\n",
    "\n",
    "\n",
    "print('MAE for Training data is', mean_absolute_error(y_train2, y_pred_poly2))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate2, y_pred_validate_poly2))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train2, y_pred_poly2)) \n",
    "print('R Squared for validation data is', r2_score(y_validate2, y_pred_validate_poly2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training data is 3.7299009713838203\n",
      "MAE for validation data is 3.6483699286260975\n",
      "R Squared for train data is 0.12874684455306662\n",
      "R Squared for validation data is -5.4657565639372585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg=PolynomialFeatures(degree=2)\n",
    "X_poly=poly_reg.fit_transform(X_train3)\n",
    "X_validate_poly=poly_reg.fit_transform(X_validate3)\n",
    "X_test_poly=poly_reg.fit_transform(X_test3)\n",
    "lin_reg_2=LinearRegression()\n",
    "lin_reg_2.fit(X_poly,y_train3)\n",
    "\n",
    "\n",
    "y_pred_poly3= lin_reg_2.predict(X_poly)\n",
    "y_pred_validate_poly3= lin_reg_2.predict(X_validate_poly)\n",
    "y_pred_test3= lin_reg_2.predict(X_test_poly)\n",
    "\n",
    "print('MAE for Training data is', mean_absolute_error(y_train3, y_pred_poly3))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate3, y_pred_validate_poly3))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train3, y_pred_poly3)) \n",
    "print('R Squared for validation data is', r2_score(y_validate3, y_pred_validate_poly3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "Poly=X_test_raw[['EPAssetsId','UWI']]\n",
    "Poly['_Normalized`IP`(Oil`-`Bbls)']=y_pred_test\n",
    "Poly['_Normalized`IP`Gas`(Boe/d)']=y_pred_test2\n",
    "Poly['_Normalized`IP`(Water`-`Bbls)']=y_pred_test3\n",
    "Poly.to_csv('D:/Submit_poly.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training data is 0.0\n",
      "MAE for validation data is 4.816907737334838\n",
      "R Squared for train data is 1.0\n",
      "R Squared for validation data is 0.43637666894349547\n"
     ]
    }
   ],
   "source": [
    "# Fitting the Regression Model to the dataset\n",
    "# Create your regressor here\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor=DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "y_pred_validate = regressor.predict(X_validate)\n",
    "y_pred_test = regressor.predict(X_test)\n",
    "print('MAE for Training data is', mean_absolute_error(y_train, y_pred_train))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate, y_pred_validate))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train, y_pred_train)) \n",
    "print('R Squared for validation data is', r2_score(y_validate, y_pred_validate) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training data is 5.576563832055563e-07\n",
      "MAE for validation data is 2.0418556911320542\n",
      "R Squared for train data is 0.9999999999997411\n",
      "R Squared for validation data is 0.7640466235128855\n"
     ]
    }
   ],
   "source": [
    "# Fitting the Regression Model to the dataset\n",
    "# Create your regressor here\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor=DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(X_train2,y_train2)\n",
    "\n",
    "y_pred_train2 = regressor.predict(X_train2)\n",
    "y_pred_validate2 = regressor.predict(X_validate2)\n",
    "y_pred_test2= regressor.predict(X_test2)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE for Training data is', mean_absolute_error(y_train2, y_pred_train2))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate2, y_pred_validate2))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train2, y_pred_train2)) \n",
    "print('R Squared for validation data is', r2_score(y_validate2, y_pred_validate2) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training data is 6.069173316559825e-07\n",
      "MAE for validation data is 3.5194484487801607\n",
      "R Squared for train data is 0.9999999999987296\n",
      "R Squared for validation data is -17.23049754267089\n"
     ]
    }
   ],
   "source": [
    "# Fitting the Regression Model to the dataset\n",
    "# Create your regressor here\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor=DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(X_train3,y_train3)\n",
    "y_pred_train3=regressor.predict(X_train3)\n",
    "y_pred_validate3 = regressor.predict(X_validate3)\n",
    "y_pred_test3= regressor.predict(X_test3)\n",
    "print('MAE for Training data is', mean_absolute_error(y_train3, y_pred_train3))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate3, y_pred_validate3))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train3, y_pred_train3)) \n",
    "print('R Squared for validation data is', r2_score(y_validate3, y_pred_validate3) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "DT=X_test_raw[['EPAssetsId','UWI']]\n",
    "DT['_Normalized`IP`(Oil`-`Bbls)']=y_pred_test\n",
    "DT['_Normalized`IP`Gas`(Boe/d)']=y_pred_test2\n",
    "DT['_Normalized`IP`(Water`-`Bbls)']=y_pred_test3\n",
    "\n",
    "\n",
    "DT.to_csv('D:/Submit-DT.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training data is 1.3683735733927385\n",
      "MAE for validation data is 3.597639916509373\n",
      "R Squared for train data is 0.9552765027328275\n",
      "R Squared for validation data is 0.729042550666706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor=RandomForestRegressor(n_estimators=500,random_state=0)\n",
    "regressor.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "y_pred_validate = regressor.predict(X_validate)\n",
    "y_pred_test = regressor.predict(X_test)\n",
    "print('MAE for Training data is', mean_absolute_error(y_train, y_pred_train))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate, y_pred_validate))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train, y_pred_train)) \n",
    "print('R Squared for validation data is', r2_score(y_validate, y_pred_validate) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training data is 0.7539597121185867\n",
      "MAE for validation data is 1.883484332943892\n",
      "R Squared for train data is 0.9416224978525016\n",
      "R Squared for validation data is 0.6683253671564455\n"
     ]
    }
   ],
   "source": [
    "# Fitting the Regression Model to the dataset\n",
    "# Create your regressor here\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor=RandomForestRegressor(n_estimators=500,random_state=0)\n",
    "regressor.fit(X_train2,y_train2)\n",
    "y_pred_train2 = regressor.predict(X_train2)\n",
    "y_pred_validate2 = regressor.predict(X_validate2)\n",
    "y_pred_test2= regressor.predict(X_test2)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE for Training data is', mean_absolute_error(y_train2, y_pred_train2))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate2, y_pred_validate2))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train2, y_pred_train2)) \n",
    "print('R Squared for validation data is', r2_score(y_validate2, y_pred_validate2) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training data is 0.8643915724711397\n",
      "MAE for validation data is 2.4250151344137754\n",
      "R Squared for train data is 0.9195640916555085\n",
      "R Squared for validation data is -1.8965198951510205\n"
     ]
    }
   ],
   "source": [
    "# Fitting the Regression Model to the dataset\n",
    "# Create your regressor here\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor=RandomForestRegressor(n_estimators=500,random_state=0)\n",
    "regressor.fit(X_train3,y_train3)\n",
    "\n",
    "\n",
    "y_pred_train3=regressor.predict(X_train3)\n",
    "y_pred_validate3 = regressor.predict(X_validate3)\n",
    "y_pred_test3= regressor.predict(X_test3)\n",
    "print('MAE for Training data is', mean_absolute_error(y_train3, y_pred_train3))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate3, y_pred_validate3))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train3, y_pred_train3)) \n",
    "print('R Squared for validation data is', r2_score(y_validate3, y_pred_validate3) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "RF=X_test_raw[['EPAssetsId','UWI']]\n",
    "\n",
    "RF['_Normalized`IP`(Oil`-`Bbls)']=y_pred_test\n",
    "RF['_Normalized`IP`Gas`(Boe/d)']=y_pred_test2\n",
    "RF['_Normalized`IP`(Water`-`Bbls)']=y_pred_test3\n",
    "\n",
    "RF.to_csv('D:/Submit-RF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting SVR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_validate = sc_X.fit_transform(X_validate)\n",
    "X_test = sc_X.fit_transform(X_test)\n",
    "\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train)\n",
    "\n",
    "sc_y2 = StandardScaler()\n",
    "y_train2 = sc_y2.fit_transform(y_train2)\n",
    "\n",
    "sc_y3 = StandardScaler()\n",
    "y_train3 = sc_y3.fit_transform(y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training data is 0.7393565689512492\n",
      "MAE for validation data is 13.978358154603756\n",
      "R Squared for train data is -0.03537530056850202\n",
      "R Squared for validation data is -1.7859616591574148\n"
     ]
    }
   ],
   "source": [
    "# fitting SVR to the data set\n",
    "from sklearn.svm import SVR\n",
    "regressor=SVR(kernel='poly' , degree =2)\n",
    "regressor.fit(X_train,y_train)\n",
    "\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "y_pred_validate = regressor.predict(X_validate)\n",
    "y_pred_test = regressor.predict(X_test)\n",
    "print('MAE for Training data is', mean_absolute_error(y_train, y_pred_train))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate, y_pred_validate))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train, y_pred_train)) \n",
    "print('R Squared for validation data is', r2_score(y_validate, y_pred_validate) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-e5943ea2b53a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVR\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my_pred_train2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train1' is not defined"
     ]
    }
   ],
   "source": [
    "# fitting SVR to the data set\n",
    "from sklearn.svm import SVR\n",
    "regressor=SVR(kernel='rbf')\n",
    "regressor.fit(X_train1,y_train2)\n",
    "\n",
    "y_pred_train2 = regressor.predict(X_train)\n",
    "y_pred_validate2 = regressor.predict(X_validate)\n",
    "y_pred_test2= regressor.predict(X_test)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE for Training data is', mean_absolute_error(y_train2, y_pred_train2))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate2, y_pred_validate2))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train2, y_pred_train2)) \n",
    "print('R Squared for validation data is', r2_score(y_validate2, y_pred_validate2) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting SVR to the data set\n",
    "from sklearn.svm import SVR\n",
    "regressor=SVR(kernel='sigmoid')\n",
    "regressor.fit(X_train1,y_train2)\n",
    "\n",
    "\n",
    "y_pred_train3=regressor.predict(X_train)\n",
    "y_pred_validate3 = regressor.predict(X_validate)\n",
    "y_pred_test3= regressor.predict(X_test)\n",
    "print('MAE for Training data is', mean_absolute_error(y_train3, y_pred_train3))\n",
    "print('MAE for validation data is', mean_absolute_error(y_validate3, y_pred_validate3))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R Squared for train data is', r2_score(y_train3, y_pred_train3)) \n",
    "print('R Squared for validation data is', r2_score(y_validate3, y_pred_validate3) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "SVM=X_test_raw[['EPAssetsId','UWI']]\n",
    "SVM['_Normalized`IP`(Oil`-`Bbls)']=y_pred_test\n",
    "SVM['_Normalized`IP`Gas`(Boe/d)']=y_pred_test2\n",
    "SVM['_Normalized`IP`(Water`-`Bbls)']=y_pred_test3\n",
    "SVM.to_csv('D:/Submit-SVR.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
